{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 크롤링을 통한 데이터 수집\n",
    "웹 크롤링은 자동화된 스크립트를 사용하여 웹사이트의 데이터를 추출하는 과정이다. 이는 다양한 데이터를 수집하고 분석하는 데 유용하다.  \n",
    "웹 크롤링의 기본 개념과 주의점, HTML과 태그에 관한 설명, 그리고 실제로 데이터를 크롤링하는 예제를 다뤄보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 크롤링이란?\n",
    "웹 크롤링(Web Crawling)은 자동화된 봇을 사용하여 웹 페이지를 탐색하고, 데이터를 수집하는 기술이다. 크롤러(Crawler) 또는 스파이더(Spider)라고도 불리는 이러한 봇은 정해진 규칙에 따라 웹 페이지의 링크를 따라가면서 데이터를 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML과 태그\n",
    "- HTML(HyperText Markup Language)은 웹 페이지의 구조를 정의하는 마크업 언어다.\n",
    "- HTML은 다양한 태그를 사용하여 텍스트, 이미지, 링크 등을 표시한다. 주요 태그로는 `<div>`, `<a>`, `<p>`, `<img>` 등이 있으며, 각 태그는 고유의 속성을 가질 수 있다. 예를 들어, `<a>` 태그는 링크를 정의하며 `href` 속성을 통해 링크의 URL을 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주의점\n",
    "웹 크롤링을 할 때는 다음과 같은 주의점이 있다:\n",
    "1. **robots.txt 준수**: 웹사이트의 robots.txt 파일은 크롤러가 접근할 수 있는 영역과 접근이 제한된 영역을 정의한다. 이를 준수하여 웹사이트의 정책을 따라야 한다.\n",
    "2. **과도한 요청 자제**: 과도한 요청은 서버에 부하를 주어 서비스에 지장을 줄 수 있다. 적절한 시간 간격을 두고 요청을 보내야 한다.\n",
    "3. **저작권 준수**: 수집한 데이터는 저작권 법에 따라 사용해야 한다. 데이터의 상업적 이용이나 재배포 시 주의가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크롤링 예제\n",
    "다음은 `requests`와 `BeautifulSoup` 라이브러리를 사용하여 네이버 스포츠 뉴스 페이지에서 데이터를 크롤링하는 예제다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. '전직 삼성맨' 오재일 친정 울렸다! 동점타&멀티히트 폭발…'로하스 역전 결승포' KT, 삼성에 0:4→4:3 역전승 '위닝 달성'\n",
      "2. \"3일 푹 쉬었고, 내일도 쉰다\"…대체 마지막 날인데 2회 전격 강판, 한화 총력전 시작됐다\n",
      "3. \"와! 손흥민!! \" 손흥민과 토트넘 방한, 팬들 뜨거운 환대…벤탄쿠르 제외\n",
      "4. 홍명보 떠난 울산, 제12대 사령탑으로 김판곤 감독 선임\n",
      "5. 텐 하흐에게 버림받고 1년 동안 백수 생활…데 헤아, 1년 만에 소속팀 구하나?\n",
      "6. '7억 달러' 전혀 아깝지 않은 오타니…49홈런-40도루 페이스! '야구천재'도 ML 6번째 40:40클럽은 탐이 난다\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치 (필요한 경우 주석 해제)\n",
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "\n",
    "# 라이브러리 임포트\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 네이버 스포츠 뉴스 페이지 URL\n",
    "url = 'https://sports.news.naver.com/index'\n",
    "\n",
    "# 페이지 요청 및 HTML 파싱\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 예시: 뉴스 제목 가져오기\n",
    "news_titles = soup.select('.today_item .title')\n",
    "titles = [title.get_text().strip() for title in news_titles]\n",
    "\n",
    "# 뉴스 제목 출력\n",
    "for idx, title in enumerate(titles, 1):\n",
    "    print(f'{idx}. {title}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
