{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1장 & 2장",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwZo5uCazQd6PTzh+OIAqi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InryeolChoi/analysis_basic/blob/main/1%EC%9E%A5_%26_2%EC%9E%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-4. 구글 드라이브와 연동\n"
      ],
      "metadata": {
        "id": "Ec6t2YoLIBL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YFNM-zHFql4",
        "outputId": "e2921c43-c82b-4fc2-b9c3-04b65254fade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/gdrive/My Drive/test.txt\", 'w') as f:\n",
        "  f.writelines(\"test\")"
      ],
      "metadata": {
        "id": "_-mUK6kmIVba"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-3. 어휘집합 구축하기"
      ],
      "metadata": {
        "id": "FBH6rDXCRu9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratsnlp"
      ],
      "metadata": {
        "id": "_6St-zwQRpem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "말뭉치 내려받기 및 전처리"
      ],
      "metadata": {
        "id": "FhOXH8GHSk24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import Korpora\n",
        "nsmc = Korpora.load(\"nsmc\", force_download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWYcBxQbSM9C",
        "outputId": "b0ab1275-c3ae-4449-cdc6-7015173b81c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : e9t@github\n",
            "    Repository : https://github.com/e9t/nsmc\n",
            "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
            "\n",
            "    Naver sentiment movie corpus v1.0\n",
            "    This is a movie review dataset in the Korean language.\n",
            "    Reviews were scraped from Naver Movies.\n",
            "\n",
            "    The dataset construction is based on the method noted in\n",
            "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
            "\n",
            "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nsmc] download ratings_train.txt: 14.6MB [00:00, 113MB/s]                            \n",
            "[nsmc] download ratings_test.txt: 4.90MB [00:00, 81.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NSMC 전처리"
      ],
      "metadata": {
        "id": "hQcTAHXcSxej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def write_lines(path, lines):\n",
        "  with open(path, 'w', encoding='utf-8') as f:\n",
        "    for line in lines:\n",
        "      f.write(f'{line}\\n')\n",
        "write_lines(\"/content/train.txt\", nsmc.train.get_all_texts())\n",
        "write_lines(\"/content/test.txt\", nsmc.train.get_all_texts())"
      ],
      "metadata": {
        "id": "7fZFCOf4SiVX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "디렉터리 만들기"
      ],
      "metadata": {
        "id": "KOLO8Th3WegU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"/gdrive/My Drive/nlpbook/bbpe\", exist_ok = True)"
      ],
      "metadata": {
        "id": "mRLDE0_FTOYw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "바이트 수준 BPE 어휘 집합 구축"
      ],
      "metadata": {
        "id": "mtvEpujiXV8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "bytebpe_tokenzier = ByteLevelBPETokenizer()\n",
        "bytebpe_tokenzier.train(\n",
        "    files = [\"/content/train.txt\", \"/content/test.txt\"],\n",
        "    vocab_size = 10000,\n",
        "    special_tokens = [\"[PAD]\"]\n",
        ")\n",
        "bytebpe_tokenzier.save_model(\"/gdrive/My Drive/nlpbook/bbpe\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQK0XvrnXYWV",
        "outputId": "1bc9d00d-66f8-4d0a-ea5a-62fa08f8e94f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/My Drive/nlpbook/bbpe/vocab.json',\n",
              " '/gdrive/My Drive/nlpbook/bbpe/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "APyLsiB5X-Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"/gdrive/My Drive/nlpbook/wordpiece\", exist_ok=True)"
      ],
      "metadata": {
        "id": "GXsHRv4kX8mn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "wordpiece_tokenizer = BertWordPieceTokenizer(lowercase=False)\n",
        "wordpiece_tokenizer.train(\n",
        "    files = [\"/content/train.txt\", \"/content/test.txt\"],\n",
        "    vocab_size = 10000\n",
        ")\n",
        "wordpiece_tokenizer.save_model(\"/gdrive/My Drive/nlpbook/wordpiece\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ova-p1-2koSK",
        "outputId": "3f9d8d12-19a3-4b5c-a580-672f883c839b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/My Drive/nlpbook/wordpiece/vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-4. 토큰화하기"
      ],
      "metadata": {
        "id": "DVdLEkaqmhZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "준비코드\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KSvCX5OvmqhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratsnlp"
      ],
      "metadata": {
        "id": "NSxH8FZ7ky9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "id": "mpborpnEmn3z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT 입력값 설정"
      ],
      "metadata": {
        "id": "vu_PZompmkUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "tokenizer_gpt = GPT2Tokenizer.from_pretrained(\"/gdrive/My Drive/nlpbook/bbpe\")\n",
        "tokenizer_gpt.pad_token = \"[PAD]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNAKBdUNnEHc",
        "outputId": "5e693d4c-13e2-491f-da6e-a81186eb053b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "file /gdrive/My Drive/nlpbook/bbpe/config.json not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sentences = [\n",
        "    \"아 더빙...진짜 짜증나네요 목소리\",\n",
        "    \"연기가 별로 답이 없는 것 같다.\",\n",
        "    \"별루였다...\"\n",
        "]\n",
        "tokenized_sentences = [tokenizer_gpt.tokenize(sen) for sen in Sentences]\n",
        "tokenized_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFMrPHGUnKIF",
        "outputId": "f3b8abc6-23d9-4bfc-a6f6-431cd26f905c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ìķĦ', 'ĠëįĶë¹Ļ', '...', 'ì§Ħì§ľ', 'Ġì§ľì¦ĿëĤĺ', 'ëĦ¤ìļĶ', 'Ġëª©ìĨĮë¦¬'],\n",
              " ['ìĹ°ê¸°ê°Ģ', 'Ġë³Ħë¡ľ', 'ĠëĭµìĿ´', 'ĠìĹĨëĬĶ', 'Ġê²ĥ', 'Ġê°Ļëĭ¤', '.'],\n",
              " ['ë³Ħë£¨', 'ìĺĢëĭ¤', '...']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs = tokenizer_gpt(\n",
        "    Sentences,\n",
        "    padding = \"max_length\",\n",
        "    max_length = 12,\n",
        "    truncation = True\n",
        ")"
      ],
      "metadata": {
        "id": "Hb5gSfoxr2BK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT 입력값 만들기"
      ],
      "metadata": {
        "id": "ONTclywctc0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\n",
        "    \"/gdrive/My Drive/nlpbook/wordpiece\",\n",
        "    do_lower_case = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "negJv6R4p7I9",
        "outputId": "ed193bb2-f27e-4e35-ca1b-f7887ac90ab1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "file /gdrive/My Drive/nlpbook/wordpiece/config.json not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sentences = [\n",
        "    \"아 더빙...진짜 짜증나네요 목소리\",\n",
        "    \"연기가 별로 답이 없는 것 같다.\",\n",
        "    \"별루였다...\"\n",
        "]\n",
        "tokenized_sentences = [tokenizer_bert.tokenize(sen) for sen in Sentences]\n",
        "tokenized_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imj-TYiwtpc0",
        "outputId": "7164eb13-4d13-4617-9d7d-284dda910690"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['아', '더빙', '.', '.', '.', '진짜', '짜증나', '##네요', '목소리'],\n",
              " ['연기가', '별로', '답이', '없는', '것', '같다', '.'],\n",
              " ['별루', '##였다', '.', '.', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_inputs = tokenizer_bert(\n",
        "    Sentences,\n",
        "    padding = \"max_length\",\n",
        "    max_length = 12,\n",
        "    truncation = True\n",
        ")\n"
      ],
      "metadata": {
        "id": "-F2iN9n_t3VQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KB0iS4XVt3Er"
      }
    }
  ]
}